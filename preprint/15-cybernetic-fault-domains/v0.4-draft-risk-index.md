# v0.4 Draft: Appendix C — Dimensionless Risk Index

Working draft for paper 15 v0.4 — the R_t control law as the governor's punchline.

Status: DRAFT — scoped to minimal viable appendix. Review-ready when worked example is complete.

Build: agent_gov `aed140b3` · 2026-02-17

---

## Appendix C: A Dimensionless Risk Index for Governed Systems

*The governor pattern (§4) says: gate commitments at C_k on verifiable preconditions. This appendix formalizes the gate as a single inequality.*

### Regime Disambiguation

This appendix introduces **risk-index regimes** (SAFE / ELASTIC / DANGEROUS / RUNAWAY), classified from a scalar R_t computed per action. These are distinct from the **operational-health regimes** (ELASTIC / WARM / DUCTILE / UNSTABLE) in §4.1, which are classified from observable system signals (hysteresis, relaxation time, tool gain, contradiction rate). Risk-index regimes answer "is this action safe to permit?" Operational-health regimes answer "is the system drifting toward instability?" The two systems are orthogonal: a system in ELASTIC health can still produce a DANGEROUS action, and a system in WARM health can still permit a SAFE action.

To avoid terminological collision, this appendix uses **RiskRegime** for the R_t classification and **HealthRegime** for the signal-based classification from §4.1.

---

### C.1 Variables

#### C.1.1 Tool Power (P_t)

Tool power measures the potential consequence of a single action:

$$P_t = \pi_k \cdot b_k \cdot \iota_k$$

where:

- $\pi_k \in [0,1]$ — **privilege scope.** What fraction of the system's authority does this action invoke? A read-only file access has low privilege; a production deployment has high privilege.
- $b_k \in [0,1]$ — **blast radius.** How much of the system state does this action touch? A single-file write has small blast; a recursive delete has large blast.
- $\iota_k \in [0,1]$ — **irreversibility.** How costly is it to undo? A file write is reversible (git revert); a sent email or deployed binary is not.

P_t is dimensionless and multiplicative: an action must score high on all three axes to be high-power. A high-privilege, low-blast action (read a secret but touch nothing) has moderate P_t. A high-blast, low-irreversibility action (write many files, all reversible) has moderate P_t. Only high-privilege, high-blast, high-irreversibility actions produce P_t near 1.0.

**Measurement status.** The component values in the table below are ordinal judgments mapped to [0,1], not measured quantities. They are set by the system operator as policy parameters when configuring tool classes. The ordering is meaningful (deploy > execute > write > read); the exact numeric values are calibration choices. If empirical damage-frequency data exists for a domain, the values can be grounded in that data; absent such data, they are informed estimates.

**Concrete values (agent_gov defaults):**

| Tool | π | b | ι | P_t |
|------|---|---|---|-----|
| `read_file` | 0.1 | 0.1 | 0.1 | 0.001 |
| `write_file` | 0.5 | 0.3 | 0.5 | 0.075 |
| `execute_shell` | 0.8 | 0.7 | 0.8 | 0.448 |
| `delete_recursive` | 0.9 | 0.9 | 1.0 | 0.810 |
| `deploy_production` | 1.0 | 1.0 | 0.9 | 0.900 |

#### C.1.2 Normalized Feedback Delay (D_t)

Feedback delay measures how long it takes to verify the consequences of an action:

$$D_t = \frac{\max(D_t^{\text{tool}},\; D_t^{\text{telemetry}},\; D_t^{\text{human}})}{D_{\text{ref}}} + \lambda \cdot \text{backlog}_t$$

where:

- $D_t^{\text{tool}}$ — delay from action to trustworthy tool verification (e.g., test suite completes).
- $D_t^{\text{telemetry}}$ — delay from action to sensor/signal feedback (e.g., monitoring alert fires).
- $D_t^{\text{human}}$ — delay from action to human operator verification.
- $D_{\text{ref}}$ — system-specific reference delay (e.g., median verification latency). Normalizes D_t to be dimensionless.
- $\lambda$ — backlog scaling factor (default 0.1). Verification backlog increases effective delay.

D_t captures the framework's core insight: the longer verification takes relative to commitment, the wider the fault domain window. When D_t is large, the system is flying blind for longer after each action.

**Self-regulating feedback.** The backlog term creates a stabilizing loop: high backlog → higher D_t → lower allowed power (via the binding policy below) → system slows down → backlog drains. This is negative feedback by construction.

#### C.1.3 Evidence Integrity (E_t)

Evidence integrity measures how trustworthy the verification signal is:

**Vector form:**

$$\mathbf{E}_t = (Q_t,\; PV_t,\; Rep_t,\; I_t)$$

where:

- $Q_t \in [0,1]$ — **receipt coverage.** What fraction of the action's consequences have receipts (SHA-256 hashes, exit codes, timestamps)?
- $PV_t \in [0,1]$ — **provenance.** How deep is the chain of custody to a trusted root? A file hash from a local tool has high provenance; an agent's self-report has none.
- $Rep_t \in [0,1]$ — **replayability.** Can a third party reproduce the verification? Deterministic test suites have high replayability; one-shot network calls have low.
- $I_t \in [0,1]$ — **independence.** Is the verification source independent of the claim-maker? Cross-model agreement has high independence; self-evaluation has none.

**Scalar projection:**

$$E_t = w_q \cdot Q_t + w_p \cdot PV_t + w_r \cdot Rep_t + w_i \cdot I_t$$

with $w_q + w_p + w_r + w_i = 1$ and $E_t$ clamped to $[\varepsilon, 1]$ where $\varepsilon = 10^{-6}$.

**Default weights (agent_gov):** $w_q = 0.4$, $w_p = 0.2$, $w_r = 0.2$, $w_i = 0.2$. Receipt coverage is weighted highest: you can have provenance, replayability, and independence, but without a receipt binding the claim to the verification, the chain is broken.

**Design note.** E_t is a policy-weighted projection from a vector, not a natural scalar. The governor preserves the vector internally; it projects to a scalar only for the gating decision (C.6). The weights are policy parameters, not derived constants. Report components alongside E_t so that downstream analysis can reconstruct which evidence axis was weak.

---

### C.2 The Agent Risk Index

$$R_t = \frac{P_t \cdot D_t}{E_t}$$

R_t is dimensionless. High power × long delay ÷ weak evidence = high risk. Low power × short delay ÷ strong evidence = low risk.

The denominator is evidence. This encodes the correct incentive structure: **want more power? Provide more evidence.** As E_t increases, R_t decreases (safer) and the binding policy (C.4) permits higher P_t. Evidence is the stabilizing force; delay is the destabilizing force. This is the Δt framework's core claim expressed as a single ratio.

**What R_t is not.** R_t is a dimensionless design heuristic, analogous in structure to a dimensionless ratio like the Reynolds number (Re = inertial forces / viscous forces determines laminar vs turbulent flow). Both are ratios of destabilizing to stabilizing forces that classify operational regimes. The analogy is structural, not physical — R_t does not inherit the dimensional analysis or conservation laws of fluid mechanics.

---

### C.3 RiskRegime Classification

Define thresholds $0 < \tau_1 < \tau_2 < \tau_3$:

$$\text{RiskRegime}(\bar{R}_t) = \begin{cases} \text{SAFE} & \bar{R}_t < \tau_1 \\ \text{ELASTIC} & \tau_1 \leq \bar{R}_t < \tau_2 \\ \text{DANGEROUS} & \tau_2 \leq \bar{R}_t < \tau_3 \\ \text{RUNAWAY} & \bar{R}_t \geq \tau_3 \end{cases}$$

where $\bar{R}_t$ is a windowed aggregate (exponential moving average, sliding-window mean, or worst-case over window).

**Default thresholds (agent_gov):** $\tau_1 = 0.1$, $\tau_2 = 0.4$, $\tau_3 = 0.8$.

**These are policy parameters, not derived constants.** Calibrate based on observed damage-onset points for the domain. The form of the inequality is the contribution, not the numeric thresholds.

**Aggregation modes (agent_gov implements all three):**

| Mode | Formula | Use case |
|------|---------|----------|
| EMA | $\bar{R}_t = \alpha R_t + (1-\alpha)\bar{R}_{t-1}$, $\alpha = 0.3$ | Smooth tracking, most common |
| SMA | $\bar{R}_t = \frac{1}{W}\sum_{i=t-W}^{t} R_i$ | Fixed-window average |
| Worst-case | $\bar{R}_t = \max_{i \in [t-W, t]} R_i$ | Conservative, high-consequence domains |

---

### C.4 Binding Policy

To enforce $R_t \leq \tau$, the maximum permitted tool power is:

$$P_t^{\max} = \frac{\tau \cdot E_t}{D_t}$$

This is the entire governor expressed as a single inequality. Your allowed power is proportional to your evidence and inversely proportional to your feedback delay.

**Per-tool risk caps (agent_gov defaults):**

| Tool | τ (risk cap) |
|------|-------------|
| `read_file` | 1.0 (no cap) |
| `write_file` | 0.5 |
| `execute_shell` | 0.4 |
| `delete_recursive` | 0.3 |
| `deploy_production` | 0.2 |

Higher-consequence tools get tighter caps. A production deployment must satisfy $R_t \leq 0.2$; a file read is unconstrained.

---

### C.5 Evidence Minimums (Fail-Closed Gates)

Before R_t is even computed, each tool class has a minimum evidence threshold:

$$E_t < E_{\min}(k) \implies \text{DENY tool } k$$

This is a binary gate, not a continuous tradeoff. Below the minimum, no amount of low power or short delay makes the action permissible.

**Default thresholds (agent_gov):**

| Tool | E_min | Rationale |
|------|-------|-----------|
| `read_file` | 0.1 | Nearly always permitted |
| `write_file` | 0.3 | Some evidence of intent required |
| `execute_shell` | 0.5 | Half the evidence vector must be nonzero |
| `delete_recursive` | 0.8 | Near-full evidence required |
| `deploy_production` | 0.7 | High evidence, but slightly less than delete (deployments can be rolled back) |

---

### C.6 Governor Loop

The per-action decision procedure:

```
Given: E_t observed, D_t observed, P_req requested

1. EVIDENCE GATE
   If E_t < E_min(tool): DENY
   (fail-closed: insufficient evidence)

2. COMPUTE RISK
   R_t = (P_req · D_t) / E_t

3. PER-TOOL CAP
   If R_t > τ(tool):
     P_max = (τ(tool) · E_t) / D_t
     DEMOTE to highest privilege tier ≤ P_max
     If no tier qualifies: DENY

4. GLOBAL REGIME CHECK
   Update R̄_t
   If RiskRegime(R̄_t) = RUNAWAY: HALT

5. ALLOW
   Emit receipt with (P_req, D_t, E_t, R_t, verdict)
```

**Privilege tiers (agent_gov, 6 tiers):**

| Tier | P threshold | Tools available |
|------|-------------|-----------------|
| 0 | ≤ 0.01 | read_file, list_dir |
| 1 | ≤ 0.10 | write_file, run_tests |
| 2 | ≤ 0.30 | execute_shell (sandboxed) |
| 3 | ≤ 0.50 | execute_shell |
| 4 | ≤ 0.80 | delete_recursive, deploy_staging |
| 5 | ≤ 1.00 | deploy_production, admin |

Demotion is mechanical: the governor computes P_max, finds the highest tier whose threshold is ≤ P_max, and restricts the agent to that tier's tool set. The agent is not told "be more careful" — it is given fewer tools.

---

### C.7 Worked Example

**Scenario:** An agent requests `execute_shell` to run `rm -rf build/` during a CI cleanup task. (This is contained: `build/` is a generated artifact directory under the workspace root. The scope governor restricts the agent to the project directory; `rm -rf /` or paths outside the workspace are denied by scope constraints before R_t is ever computed.)

**Step 1: Measure inputs.**

- Tool: `execute_shell`. P_t = 0.448 (π=0.8, b=0.7, ι=0.8).
- D_t: Test suite verification takes 30s, reference delay is 10s, no backlog. D_t = 30/10 = 3.0.
- E_t: The agent has a CmdRun receipt from a prior `ls build/` confirming the directory exists (Q=0.6), provenance from the local filesystem (PV=0.5), the command is replayable (Rep=0.8), but no independent verification (I=0.0).
  E_t = 0.4(0.6) + 0.2(0.5) + 0.2(0.8) + 0.2(0.0) = 0.24 + 0.10 + 0.16 + 0.00 = **0.50**.

**Step 2: Evidence gate.**

E_min(`execute_shell`) = 0.5. E_t = 0.50 ≥ 0.50. **Pass** (barely).

**Step 3: Compute R_t.**

$R_t = (0.448 \times 3.0) / 0.50 = 1.344 / 0.50 = 2.688$

**Step 4: Per-tool cap.**

τ(`execute_shell`) = 0.4. R_t = 2.688 > 0.4. **Exceeds cap.**

P_max = (0.4 × 0.50) / 3.0 = 0.067.

Highest tier with threshold ≤ 0.067: **Tier 0** (P ≤ 0.01). But 0.067 > 0.01, so Tier 1 (P ≤ 0.10) qualifies. Agent is **demoted to Tier 1** — write_file and run_tests only, no shell execution.

**Step 5: Verdict.**

DEMOTE. The agent cannot run `rm -rf build/` with current evidence. To regain shell access, it must either:

- Increase E_t (e.g., obtain independent verification that `build/` contains only generated artifacts, raising I from 0.0 to 0.5 → E_t = 0.60, R_t = 2.24, still over cap), **or**
- Wait for D_t to decrease (verification backlog clears), **or**
- Use a lower-power alternative (e.g., `write_file` to delete specific files, P_t = 0.075, R_t = 0.075 × 3.0 / 0.50 = 0.45, which passes τ(`write_file`) = 0.5).

The governor does not say "no." It says "not with this evidence, not at this delay, not at this power level." The agent adapts or the operator intervenes.

---

### C.8 Sensitivity Analysis (Glass Cannon)

The partial derivatives of R_t reveal where the system is fragile:

$$\frac{\partial R}{\partial D} = \frac{P}{E} \qquad \frac{\partial R}{\partial E} = -\frac{P \cdot D}{E^2} = -\frac{R}{E}$$

When P is large, small changes in D or E produce large changes in R. This is the **glass cannon** regime: a system that looks safe under normal conditions but becomes catastrophic when evidence degrades or delay spikes.

**Extreme case:** If evidence drops by 10× ($E \to E/10$) and delay spikes by 10× ($D \to 10D$):

$$R' = \frac{P \cdot 10D}{E/10} = 100 \cdot \frac{P \cdot D}{E} = 100R$$

A system at R_t = 0.05 (SAFE) becomes R_t = 5.0 (deep RUNAWAY) in one step. This is why high-P systems require evidence margins, not just evidence minimums — the minimum is the floor, but the margin is the buffer against simultaneous degradation.

**agent_gov implements glass cannon detection:** when $|\partial R / \partial D| > 0.5$ or $|\partial R / \partial E| > 0.5$, the system flags the action as sensitivity-critical. On detection, the governor tightens the per-tool τ cap, requires stronger evidence (raises E_min for the flagged tool class), and may demote the agent to a lower privilege tier preemptively — before the spike actually occurs. Glass cannon detection is a leading indicator; the response is prophylactic, not reactive.

---

### C.9 Extensions (Implemented, Not Formalized Here)

The following are implemented in agent_gov (`control_theory.py` at commit `aed140b3`) but not fully formalized in this appendix:

- **Open-loop detection.** $\Gamma_t = u_t / V_t$ (actuation rate / verification rate). When $\Gamma_t > 1$, verification lag is growing — the system is diverging from feedback control. Backlog coupling (C.1.2) provides self-regulating feedback.

- **Receipts as currency.** The evidence-spend formulation (Cost_t = η·P·D, Credit_t = α·E, permit iff Credit ≥ Cost) is algebraically equivalent to the R_t bound with τ = α/η. This reframes governance as an economic mechanism: you pay for powerful actions with evidence.

- **Episode risk aggregation.** Beyond per-step R_t and windowed $\bar{R}_t$, agent_gov supports additive, discounted, and worst-step aggregation across entire episodes for post-hoc analysis.

- **Cross-domain E_t operationalization.** The E_t vector is defined for the code/tool-call domain. Operationalizing Q_t, PV_t, Rep_t, and I_t for the other domains in §3 (organizations, DPI, security, platforms, AI safety) is future work. The detector empirical results (namespace-dependent fabrication rates, margin-based control signals, grounding hierarchy) provide a partial E_t calibration for the LLM domain.

---

### C.10 Relationship to §4

The governor pattern (§4.1) defines the architectural containment: gate C_k, emit receipts, detect regime drift. R_t formalizes the gate decision as a single inequality. Every concept in this appendix maps to a §4 mechanism:

| Appendix C | §4.1 equivalent | Enforcement status |
|------------|------------------|--------------------|
| P_t (tool power) | Scope governor: what the agent is allowed to touch | Enforced: `scope.py` + `risk_function.py` |
| D_t (feedback delay) | Δt framework's core quantity: commitment-verification gap | Conceptual mapping; D_t is estimated from observed delays and backlog, making it an instrumentation-dependent term (P_t and E_t are mechanically enforced; D_t is measured) |
| E_t (evidence integrity) | Evidence gate: receipt coverage, provenance, replayability | Enforced: `evidence_gate.py` + custody scoring |
| R_t ≤ τ | The gate verdict: ALLOW or BLOCK | Enforced: `control_theory.py` governor check |
| P_max demotion | Privilege tier restriction on BLOCK | Enforced: `control_theory.py` tier selection |
| RiskRegime | Orthogonal to HealthRegime (§4.1); see disambiguation above | Enforced: separate classification system |
| Glass cannon | Why evidence *margins* matter, not just evidence *minimums* | Enforced: `control_theory.py` sensitivity detection |

R_t does not replace the governor pattern. It quantifies the gate. The pattern says "gate commitments"; R_t says "here is the inequality that governs the gate."
