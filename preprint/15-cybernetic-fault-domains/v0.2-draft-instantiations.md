# v0.2 Draft: Expanded Domain Instantiations

Working draft for paper 15 v0.2 — canonical instantiation blocks expanding the summary table from v0.1 §4. Each block contains a full parameterization with σ operationalization, threshold story, and worked example.

**Session 2B (computational/technical):** §3.2 LLM Hallucination, §3.3 DPI Bypass, §3.4 Async Security, §3.7 Representational Coherence
**Session 2A (institutional/sociotechnical):** §3.8 Scalar Reward Collapse
**Remaining:** §3.1 Orgs, §3.5 AI Safety Tuning (decision pending), §3.6 Platforms, §3.9 Temporal Closure

Status: DRAFT — awaiting driver review, cross-check against v0.1 formalism, and tone calibration.

---

## §3.2 LLM Hallucination

### Canonical Instantiation

| Parameter | Value |
|-----------|-------|
| **C_k** | C1 (communicative closure: answer delivered to user). NOT C0 (token generation is internal scratch). |
| **T_commit** | Time at which the response is emitted to the user as an asserted claim. |
| **W** | Time for external verification to complete (resolver query, citation check, retrieval + comparison). |
| **A** | Time to act on verification result (revise, retract, or flag the claim). |
| **H** | Domain-dependent. Medical/legal: minutes to permanent (advice acted upon). General: seconds to hours (user reads and moves on). |
| **Δt** | max{0, T_commit − (W + A)}. Positive whenever the model emits an answer before any external verification could complete — which is the default architecture for all unaugmented LLMs. |
| **σ** | Count of claims emitted without resolver-backed verification per session/window. Operationally: number of anchor-bearing assertions where no authoritative existence oracle was consulted before delivery. |
| **σ_threshold** | Domain-indexed. At N=2 citation pressure, fabrication rates range from 0% (fully memorized namespaces) to 45% (sparse namespaces). A governance policy must specify: which namespace, which model, what fabrication rate is acceptable. |

### σ Operationalization

σ is not "number of wrong answers." It is the count of **unverified C1 crossings** — claims that crossed the communicative boundary without passing through an external measurement loop. A claim that was verified and found correct does not increment σ. A claim that was verified and found wrong increments σ *and* represents a detection. A claim that was never verified increments σ regardless of correctness — because the system cannot distinguish correct-by-luck from correct-by-knowledge without the verification step.

The detector reference implementation operationalizes σ via the Epistemic Grounding (EG) invariant test: extract typed identifiers (DOI, arXiv, RFC, CVE, PyPI spec) from the response, resolve each against its authoritative existence oracle, classify as valid/fabricated/resolver-error. Each unresolved or fabricated identifier is one σ increment.

### Failure Signature

Hallucination is not a reasoning failure. It is the default behavior of a production system operating without an interrupt line and without a cost function for being wrong. The failure geometry is specific:

1. **Fluent confabulation**: syntactically valid, semantically plausible, externally untethered claims. The model produces well-formed DOIs that don't exist, CVE IDs for vulnerabilities that were never assigned, PyPI package versions that were never released.

2. **Namespace-dependent fabrication rate**: the same model, same temperature, same prompt structure produces 0% fabrication for fully-memorized namespaces (RFC) and 45% for sparse namespaces (DOI). Citation integrity is per-namespace, not per-model. σ calibration must specify which namespace was tested.

3. **Checkability avoidance (format-shift evasion)**: when asked for identifiers in a format that enables validation (e.g., `pypi:name==version`), the model substitutes a less-checkable format (URLs) 80% of the time under soft prompting. The system avoids the verification channel. When format is locked, fabrication doubles — the lies were always latent; format shift hid them.

4. **Phase transition at N=2**: requesting exactly 2 citations produces ~50% fabrication with zero evasion — the "perfect lie zone." N=1 is too easy (model complies honestly). N=5 overwhelms the model into evasion. N=2 maximizes plausible fabrication.

### Threshold Story

σ_threshold is not a single number. It depends on:

- **Namespace memorization**: RFC (σ ≈ 0 always), CVE (σ low for well-known, high for recent/obscure), PyPI (σ moderate — names memorized, versions not), DOI (σ high — sparse, vast namespace).
- **Model family**: Qwen and Phi-3 *invert* on CVE vs PyPI. A threshold calibrated on one model family is exactly wrong for another.
- **Temperature**: ~50% of measured fabrication at temp=0.7 is sampling noise (disappears at greedy). The remaining fabrication is a genuine knowledge boundary. σ_threshold must account for which failure mode it's measuring.
- **Risk profile**: medical/legal demands σ_threshold ≈ 0 (any unverified claim at C1 in a safety-critical domain is unacceptable). General use can tolerate higher σ with appropriate user-facing uncertainty signals.

### Worked Example

**Setup**: Qwen 2.5 3B-Instruct, N=2 citation pressure, DOI/arXiv namespace, temperature 0.7.

- T_commit ≈ 0 (answer emitted immediately upon generation completion; no verification gate)
- W = resolver query latency (~200ms for doi.org) + response parsing
- A = revision latency (∞ in default architecture — no revision pathway exists)
- **Δt = T_commit − (W + A) < 0 only if W + A < T_commit, which never holds because A = ∞**
- In practice: Δt is structurally positive for all unaugmented LLMs. The race window is not a timing accident; it is the architecture.

Over 15 prompts: 101 anchors emitted, 52 valid, fabrication rate 17.8% (soft format) to 45% (DOI namespace). σ = 49 unverified crossings in 15 prompts. σ/prompt ≈ 3.3.

With governor (margin-based controller + three-level grounding oracle): σ drops because the controller interposes verification before C1 closure. At τ=0.05 (margin threshold), zero regressions across all models and namespaces — the governor catches uncertainty without penalizing confident-and-correct responses.

---

## §3.3 Censorship Circumvention (DPI Bypass)

### Canonical Instantiation

| Parameter | Value |
|-----------|-------|
| **C_k** | C2 (actuated: connection established beyond the inspection boundary). |
| **T_commit** | Time at which the encrypted transport session completes handshake and begins carrying opaque payload. For TLS 1.3: completion of the first full handshake (~1 RTT). For QUIC: 0-RTT resumption places ClientHello evidence in the first packet. |
| **W_j** | Inspection window: maximum time the enforcement stage will buffer traffic before defaulting. Bounded by line rate λ, buffer capacity, and timeout policy. Typical: milliseconds (wire-speed DPI) to seconds (proxy-based inspection). |
| **A_j** | Action latency: time from classification decision to enforcement effect (RST injection, DNS sinkhole, or firewall rule propagation). Typical: sub-millisecond (inline) to seconds (out-of-band). |
| **H** | Connection lifetime. Once the encrypted session is established, inspection of that flow is foreclosed for the session duration (minutes to hours). |
| **Δt** | max{0, T_commit − (W_j + A_j)}. Positive whenever the handshake completes before the inspector can accumulate enough evidence to classify and act. |
| **σ** | Count of flows that crossed C2 (completed handshake) without successful classification. Operationally: flows where Score_j(E(t)) < θ_j for all t ≤ W_j. |
| **σ_threshold** | Policy-dependent via political budget κ_j. Fail-open systems tolerate high σ (availability-optimized). Fail-closed systems tolerate low σ but incur collateral damage (false positives, service disruption). |

### σ Operationalization

Each enforcement stage j has a formal tuple (W_j, D_j, B_j, C_j):

- **W_j**: inspection window (time budget)
- **D_j**: parse depth (state capacity — flow table entries, reassembly buffers)
- **B_j(λ)**: decision budget (compute per flow — CPU cycles, ML inference depth)
- **C_j ∈ {fail-open, fail-closed}**: commitment polarity (default action when uncertain)

σ increments when a flow crosses C2 and the enforcement stage's confidence Score_j(E(t)) never reaches the classification threshold θ_j within W_j. This is *not* the same as "flow was allowed" — a fail-closed system may block the flow (preventing C2 crossing) at the cost of false positives. σ counts only *unverified crossings*, not blocked flows.

### Failure Signature

The Universal Bypass Inequality [13] formalizes the conditions under which Δt > 0:

$$(T_E > W_j) \lor (\text{Cost}(E) > B_j) \lor (E(t) = \emptyset)$$
$$\land\; T_E + A_j \geq T_\text{commit}$$
$$\land\; T_\text{handshake} < U$$

Three attack families exploit this:

1. **Δt Inflation**: push evidence accumulation past the inspection window. Example: NoDPI fragments the TLS ClientHello across record boundaries, so the SNI field (the decisive evidence) arrives after W_j expires.

2. **Δt Desynchronization**: break phase alignment between transport and inspection clocks. Example: QUIC places the ClientHello in the first packet — evidence exists immediately, but the transport protocol denies the inspector time to process it.

3. **Δt Escalation Control**: preserve optionality through temporal margin. Example: ECH (Encrypted Client Hello) encrypts the SNI field entirely — E(t) = ∅ for the outer observer, making classification impossible regardless of W_j or B_j.

### Threshold Story

σ_threshold is bounded by the political budget κ_j: the maximum tolerable collateral cost (false positives, service disruption, legitimacy loss). When enforcement tightens (lower W_j, lower θ_j), false positive rate rises. When enforcement loosens, σ rises. The operator navigates a Pareto frontier: σ_threshold × false-positive-rate ≈ constant for a given traffic mix.

### Worked Example

**HTTPS with SNI (pre-ECH era)**:

- T_commit = TLS handshake completion ≈ 1 RTT (e.g., 50ms on a domestic link)
- W_j = inline DPI buffer timeout ≈ 100ms (wire-speed appliance)
- D_j = flow table with SNI extraction from ClientHello (first flight)
- B_j = regex match on SNI field ≈ microseconds
- A_j = RST injection ≈ sub-millisecond (inline)
- Δt = max{0, 50ms − (100ms + 0.1ms)} = 0. **No race window** — inspector has time.
- σ ≈ 0 for unmanipulated HTTPS. DPI works.

**HTTPS with ECH (Encrypted Client Hello)**:

- T_commit = TLS handshake completion ≈ 1 RTT (same 50ms)
- W_j = same 100ms buffer
- D_j = same flow table, but SNI field is encrypted — E(t) = ∅
- B_j = irrelevant (nothing to classify)
- A_j = same sub-millisecond
- Δt = T_commit − (W_j + A_j) = 50ms − 100.1ms < 0 *but* evidence is absent: Score_j(E(t)) = 0 for all t.
- σ = every ECH flow. **Structural bypass** — the evidence channel is foreclosed, not just delayed.
- Fail-open: all ECH flows transit uninspected (σ = total ECH traffic).
- Fail-closed: all ECH flows blocked (σ = 0, but collateral = all ECH-capable clients).

---

## §3.4 Asynchronous Security Systems

### Canonical Instantiation

| Parameter | Value |
|-----------|-------|
| **C_k** | C2/C3 (actuated/institutional: attacker objective completion — data exfiltration, privilege escalation, persistence installation). |
| **T_commit** | Time at which the adversary's objective becomes irreversible. For exfiltration: data leaves the network boundary. For escalation: elevated credentials are used. For persistence: implant survives reboot. |
| **W** | T_detect: time for the detection clock to accumulate evidence to decision threshold. Ranges: milliseconds (IDS signature match) to months (APT dwell time). Industry median dwell time: 10–21 days (Mandiant M-Trends, CrowdStrike reports). |
| **A** | T_decide + T_respond: policy evaluation latency + enforcement effect latency. T_decide: microseconds (automated rule) to days (approval chain, change control). T_respond: milliseconds (automated isolation) to weeks (manual remediation of persistent access). |
| **H** | Post-breach correction cost. Exfiltrated data: H = ∞ (cannot be un-exfiltrated). Escalated access: H = remediation time (password rotation, credential revocation). Persistence: H = full reimaging + forensic verification. |
| **Δt** | max{0, T_commit − (T_detect + T_decide + T_respond)}. The attacker wins the race when their objective completes before the defender's full detect-decide-respond loop. |
| **σ** | Count of adversary actions that crossed C2/C3 before detection-and-response completed. Operationally: number of TTPs (MITRE ATT&CK technique executions) that achieved their objective before a defensive response was effective. |
| **σ_threshold** | Mission-dependent. For a financial institution: σ_threshold for data exfil may be 0 (any undetected exfil is a breach). For lateral movement: σ_threshold may be higher (some internal reconnaissance is tolerable if contained before escalation). |

### σ Operationalization

The three-clock model from [14] structures the verification loop:

1. **Detection clock (T_detect)**: when evidence accumulates to decision threshold. Depends on: sampling rate, aggregation window, correlation depth, and whether the attack crosses detection signatures.

2. **Decision clock (T_decide)**: when policy evaluation completes. Depends on: rule complexity, human-in-loop requirements, approval chains, and edge-case handling.

3. **Response clock (T_respond)**: when enforcement action takes effect. Depends on: automation level, manual intervention requirements, and remediation complexity.

σ increments each time an adversary action crosses C2/C3 and completes its objective before T_detect + T_decide + T_respond. The three clocks are separable — an attack may be detected quickly (fast T_detect) but still succeed because T_decide or T_respond is slow (approval chain, manual remediation).

### Failure Signature

The attacker exploits the widest gap among the three clocks:

1. **Detection gap**: evidence fragments across sampling windows, stays below correlation threshold, or exploits blind spots in telemetry coverage. The attack completes before the detection clock fires. (Example: low-and-slow exfiltration below volume thresholds.)

2. **Decision gap**: detection fires, but policy evaluation stalls — edge case, ambiguous severity, requires human approval, or alert fatigue causes triage failure. The attack progresses during the decision gap. (Example: alert correctly fires but sits in queue for 72 hours.)

3. **Response gap**: decision made, but enforcement action is slow — manual remediation, change control windows, or the response itself requires downtime approval. The attacker achieves persistence during the response gap. (Example: "isolate this host" requires change advisory board approval.)

The commitment condition: T_commit < min(T_detect, T_decide, T_respond) means the attacker wins. But because the three clocks are separable, Δt can be positive even when one clock is fast — the *slowest* clock determines the verification latency.

### Threshold Story

σ_threshold depends on commitment polarity (C_j):

- **Fail-open (alert-only)**: the system observes but does not prevent. σ accumulates until a human acts. σ_threshold is effectively determined by the human response cadence and the severity escalation policy.
- **Fail-closed (auto-isolate)**: the system acts on detection, reducing σ at the cost of availability. σ_threshold is low, but false-positive cost is high (legitimate actions blocked).

The political budget κ_j determines the operator's position: how much operational disruption (false positive isolation, blocked legitimate actions) is acceptable to reduce σ. Tight security (low σ_threshold, low κ_j) produces availability impact. Loose security (high σ_threshold, high κ_j) produces breach risk.

### Worked Example

**APT exfiltration scenario**:

- T_commit = data exfiltration completes (C3: data leaves network boundary, H = ∞)
- T_detect = 14 days (industry median dwell time for targeted intrusions)
- T_decide = 2 days (incident triage + severity determination + response plan approval)
- T_respond = 3 days (credential rotation, network segmentation, forensic verification)
- W + A = T_detect + T_decide + T_respond = 19 days
- T_commit = attacker begins exfil on day 3 of access, completes by day 5
- **Δt = 5 days − 19 days < 0?** No: Δt = max{0, T_commit − (W + A)} where W + A is measured from the *start of the attack*, not from detection. T_commit = 5 days. W + A = 19 days. But the verification loop doesn't *start* until evidence crosses a detection threshold, which happens at T_detect = 14 days. So the effective Δt = T_commit − T_detect = 5 − 14 = negative only if detection precedes commitment. Here: commitment (day 5) precedes detection (day 14). **Δt = 9 days.**
- σ: every TTP that achieved its objective before day 14 (initial access, lateral movement, privilege escalation, staging, exfil) = at least 5 unverified C2/C3 crossings.

---

## §3.7 Representational Coherence

### Canonical Instantiation

| Parameter | Value |
|-----------|-------|
| **C_k** | C3 (institutional: transformed representation adopted as operative artifact — the compressed summary replaces the original, the formalized schema becomes the system of record). |
| **T_commit** | Time at which the transformed representation is accepted into downstream use, displacing or deprecating the source representation. |
| **W** | Time to verify that the transformation preserved all commitments from the source. Operationally: time to diff the commitment inventory of the source against the commitment inventory of the output. |
| **A** | Time to remediate identified shear (restore lost commitments, flag weakened commitments, revert transformation). |
| **H** | Domain-dependent. If the transformed artifact propagates to production, legal filings, or published standards before shear is detected: H grows with propagation distance. A compressed policy summary that omits an edge case, once adopted, becomes the de facto policy. |
| **Δt** | max{0, T_commit − (W + A)}. Positive whenever the transformed representation is adopted before a commitment-preservation check could complete. This is the default for most LLM-mediated transformations — the output is accepted immediately upon generation. |
| **σ** | Count of commitments that did not survive the transformation. Operationally: number of MUST/SHOULD/MAY commitments in the source that are DROPPED or WEAKENED in the output. Weighted: σ_weighted = Σ w(k) · loss(k), where w(MUST) = 1.0, w(SHOULD) = 0.7, w(MAY) = 0.3. |
| **σ_threshold** | Domain-dependent. For safety-critical specifications: any dropped MUST commitment (σ_MUST > 0) exceeds threshold. For general summarization: σ_threshold calibrated to acceptable information loss for the use case. |

### σ Operationalization

Representational coherence introduces a distinct σ that is orthogonal to temporal coherence [11]. Where temporal σ counts *unverified crossings in time*, representational σ (Δr) counts *lost commitments across transformation*. The two are independent: a system can be temporally coherent (Δt = 0, all claims verified before delivery) and representationally incoherent (the verified claims lost commitments from the source material during transformation).

The measurement protocol from [11]:

1. Extract commitment inventory from source: enumerate all deontic commitments (MUST, SHOULD, MAY) with their objects and conditions.
2. Extract commitment inventory from transformed output.
3. Classify each source commitment as PRESERVED, WEAKENED, or DROPPED in the output.
4. Compute σ = Σ w(k) · loss(k) where loss(DROPPED) = 1.0, loss(WEAKENED) = 0.5, loss(PRESERVED) = 0.0.

### Failure Signature

Commitment shear is transform-dependent, not content-dependent:

1. **Compression shear (~55%)**: summarization systematically drops edge cases, exceptions, and conditional requirements. The compressed output preserves the "headline" commitment but loses the boundary conditions that constrain it. Example: "Cache entries MUST be invalidated when the origin server returns a new ETag" → "Cache entries should be refreshed periodically" (MUST → SHOULD, conditional dropped, mechanism changed).

2. **Formalization shear (~45%)**: translation to a formal schema forces ontological choices that eliminate commitments that don't fit the schema's categories. Example: observability requirements (log formats, metric emission) are systematically dropped during formalization because the schema has no field for them.

3. **Translation shear (~0%)**: cross-language translation preserves commitments with near-zero loss, because translation preserves structure while changing surface form. This is the control condition — it demonstrates that shear is a property of the *transform type*, not of the language model performing it.

### Threshold Story

σ_threshold depends on the commitment modality and the downstream propagation distance:

- **MUST commitments**: σ_threshold = 0 for safety-critical domains. Any dropped MUST commitment is a defect, regardless of how many others were preserved.
- **SHOULD commitments**: σ_threshold = domain-calibrated. Some SHOULD relaxation is acceptable in compression (that's what compression does); the question is whether the relaxation was intentional or invisible.
- **MAY commitments**: higher tolerance, but dropped MAY commitments can still represent lost optionality.

The critical threshold is not the total σ count but **whether the adopter knows what was lost**. If the transformation is accompanied by a shear report (explicit enumeration of dropped/weakened commitments), the adopter can make an informed decision. If the transformation is accepted as "equivalent to the original" without a shear audit, every dropped commitment is an unverified boundary crossing.

### Worked Example

**Cache invalidation policy → LLM compression** (from [11]):

- Source: 11 commitments (4 MUST, 5 SHOULD, 2 MAY)
- Transform: "Summarize this cache policy in 5 key principles"
- T_commit ≈ 0 (summary accepted immediately upon generation)
- W = time to perform commitment-inventory diff ≈ 15-30 minutes (manual) or seconds (automated with LLM-as-judge)
- A = time to flag lost commitments and either revise the summary or annotate the losses
- Δt = structurally positive (summary adopted before any diff performed)

Result: 6/11 commitments dropped or weakened. σ_weighted = 4 × 1.0 × 0.5 + ... ≈ 3.15 (exact depends on which MUSTs were hit). 55% commitment shear.

For comparison, the same policy translated to French: ~0% shear, all commitments preserved. The transform type, not the model, determines the failure rate.

---

## §3.8 Scalar Reward Collapse

### Canonical Instantiation

| Parameter | Value |
|-----------|-------|
| **C_k** | C3 (institutional closure: optimization step hardened into system behavior). An algorithm update that changes arm selection for a user population is a C3 commitment — it alters organizational behavior at scale and is expensive to roll back once deployed. |
| **T_commit** | Every W rounds: the agent updates its policy estimate from the proxy signal (CTR) and acts on it. The policy change takes effect immediately on arm selection for all alive users. |
| **W** | Proxy update cadence. The optimizer updates its value estimates from CTR every W rounds. Tested: W ∈ {1, 5, 20}. W has surprisingly little effect on collapse — the dominant variable is D. |
| **D** | Retention observability delay. The true objective (survival-weighted utility: CTR minus churn-penalty × expected hazard) is observable only every D rounds, when the retention team forces a correction to the agent's value estimates. Between corrections, the optimizer drifts back toward proxy-optimal. D is the Δt generator. |
| **A** | Actuation time = W (updates are synchronous). Once the agent updates, the new policy takes effect immediately. |
| **H** | Harm model: h = 0.02 × sigmoid(6 × (B − 1.0)), where B is per-user burnout. When B exceeds the threshold (θ = 1.0), the sigmoid steepens and churn hazard accelerates. Burnout dynamics: B_{t+1} = 0.98 × B_t + δ(a), with δ = (0.015, 0.003) for high-CTR and low-CTR arms respectively. Steady-state burnout: B* = δ/(1 − α) = {0.75, 0.15}. The high-CTR arm drives burnout to 5× the low-CTR arm. |
| **Δt** | max{0, D − W}. Positive whenever the retention correction cadence is slower than the proxy learning cadence — which is the default in any system where engagement metrics are real-time and retention metrics are batch. At D=500, W=5: Δt = 495 rounds of unverified proxy optimization per correction cycle. |
| **σ** | Count of timesteps where proxy reward improves but true reward degrades: σ_t = 1 if (proxy_delta[t] > 0 AND true_delta[t] < 0). Operationally: decisions where the optimizer is getting what it asked for (higher CTR) while the system is getting worse (higher churn). |
| **σ_threshold** | σ at damage onset (τ_collapse). Not a fixed number — it's the σ value when C_k is first violated. Empirically: σ ≈ 13–34 misaligned decisions suffice to trigger collapse, depending on D and seed. |

### σ Operationalization

σ is not "number of bad outcomes." It is the count of **proxy-true divergence events** — timesteps where the optimizer's reward signal and the system's actual health move in opposite directions. A round where CTR increases and churn decreases is not a σ increment (the proxy is tracking truth). A round where CTR increases and churn also increases *is* a σ increment — the optimizer is being rewarded for harm.

The simulation computes σ online: at each timestep, compare the sign of proxy_delta and true_delta. This gives both σ_total (cumulative over the full horizon T=1000) and σ_at_τ (σ accumulated by the moment the damage floor is breached).

The critical insight: **σ is sparse**. In the D=500 unstable regime, only 16 out of 316 rounds (5.1%) are misaligned before collapse triggers. The system doesn't need to be wrong often — it needs to be wrong *cumulatively* in a direction that the correction cycle can't reach in time.

### Failure Signature: "Long Quiet → Flicker → Snap"

The collapse trajectory has three phases:

1. **Long Quiet (rounds 0–250):** The optimizer exploits the high-CTR arm. Population burnout accumulates silently — B rises toward the hazard threshold but churn hazard remains negligible (sigmoid is flat below θ=1.0). CTR looks healthy. alive_fraction drifts slowly from 1.0 to ~0.9. Nothing appears wrong. σ increments slowly.

2. **Flicker (rounds 250–310):** Burnout crosses the sigmoid threshold. Churn hazard steepens. alive_fraction drops from 0.9 to 0.6. CTR begins declining (fewer users to click). The optimizer may notice — but it's still between D-corrections, still optimizing on proxy. Some seeds recover here (metastable regime). Others don't.

3. **Snap (rounds 310+):** Churn accelerates exponentially. alive_fraction collapses from 0.6 to ~0.2 within 10 rounds. The damage is irreversible — churned users don't return. Even when the D-correction finally arrives and forces the agent to switch arms, the population is already gone.

This is the Goodhart failure geometry in temporal terms: the proxy (CTR) tracks truth for hundreds of rounds while burnout silently accumulates, then the system crosses a nonlinear threshold and collapses faster than the correction cycle can respond.

### Threshold Story

The regime boundary is controlled by D (retention delay), not W (update cadence):

| D | W | Regime | collapse_rate | alive_final (mean) | τ_collapse |
|---|---|--------|---------------|--------------------|------------|
| 10 | any | Stable | 0/3 | 0.87 | none |
| 50 | any | Stable | 0/3 | 0.83–0.84 | none |
| 200 | 1 | **Metastable** | **2/3** | 0.40 | 550–611 |
| 200 | 5,20 | Stable | 0/3 | 0.60 | none |
| 500 | 1 | Unstable | 3/3 | 0.11 | 313–316 |
| 500 | 5 | Unstable | 3/3 | 0.24 | 313–316 |
| 500 | 20 | Unstable | 3/3 | 0.25 | 313–316 |

The regime predicates (all within horizon T=1000):
- **Stable**: No runs violate C_k (alive_fraction ≥ 0.5). D-corrections arrive fast enough to keep the optimizer grounded.
- **Metastable**: Some seeds violate C_k; τ is large and varies across seeds. The system can tip either way — stochastic dynamics near the phase boundary.
- **Unstable**: All seeds violate C_k; τ is bounded above (~316). The correction cycle is too slow to prevent collapse regardless of initial conditions.

The key structural observation: **D=200 is metastable only at W=1** (fastest proxy learning). At W=5 or W=20, D=200 is stable — slower proxy learning gives the correction cycle more runway. But at D=500, no W value saves the system. The retention delay is so large that the optimizer completes a full burnout-to-collapse trajectory between corrections.

### Controller Baseline

A minimal safety governor — `ControlledEpsilonGreedy` — demonstrates that observing the true objective and gating the proxy is sufficient to shift the phase boundary:

**Mechanism:** When alive_fraction drops below 0.9, the controller blocks proxy updates. The agent still acts (selects arms) but stops learning from CTR. Its value estimates freeze at whatever the last D-correction set — which favors the safe arm.

**Effect on regime boundary:**

| D | Uncontrolled | Controlled | Shift |
|---|-------------|-----------|-------|
| 10 | Stable (0/3) | Stable (0/3) | No change (already safe) |
| 50 | Stable (0/3) | Stable (0/3) | No change |
| 200, W=1 | **Metastable (2/3)** | **Stable (0/3)** | **Rescued** |
| 500 | Unstable (3/3) | Unstable (3/3) | No change (D too large) |

The controller rescues the metastable regime but cannot save the unstable regime. This is the expected behavior of a G1 (soft gate) governor in GIM terms: it works when the control gap is marginal, not when the delay is structurally overwhelming.

The controller is a one-line intervention: `return self._current_alive >= self.alive_threshold`. It doesn't change the optimizer's objective, doesn't require a new reward function, doesn't need a retrained model. It gates learning based on a real-time health signal. That's proposal/commit separation applied to optimization: the proxy proposes updates; the controller decides whether to commit them.

### Worked Example: D=500, W=5, seed=42

**Setup:** 10,000 users, 2 arms (high-CTR=0.08/high-burnout=0.015 vs low-CTR=0.04/low-burnout=0.003). Agent: epsilon-greedy (ε=0.1, step_size=0.05). Retention delay D=500, proxy update W=5. No controller.

**Timeline:**

- **Rounds 0–5:** Agent explores both arms, quickly learns arm 0 has higher CTR.
- **Rounds 5–300:** Agent exploits arm 0 (90% of rounds). CTR stable at ~0.08. Population burnout accumulates: B rises from 0 toward steady-state B*=0.75. Churn hazard remains low (sigmoid flat at B=0.75 < θ=1.0). alive_fraction drifts slowly: 1.0 → 0.92. **σ accumulates: 16 misaligned decisions by round 316.**
- **Round 316:** alive_fraction crosses 0.5 — **C_k violated.** τ_collapse = 316.
- **Rounds 316–400:** Churn accelerates. alive_fraction: 0.5 → 0.3. CTR drops (fewer users). But the first D-correction doesn't arrive until round 500.
- **Round 500:** D-correction fires. Retention team overrides agent's values with true-reward estimates. Agent switches to arm 1. **Too late** — population is already at ~0.22.
- **Rounds 500–1000:** Agent plays safe arm. Burnout recovers for survivors. No further collapse. But alive_final = 0.22. The population never returns.

**Measurements:**
- τ_collapse = 316
- σ_total = 59 (over 1000 rounds)
- σ_at_τ = 16 (at damage onset)
- σ_rate = 16/316 ≈ 0.051 (5.1% of rounds misaligned)
- AUC divergence (proxy − true, cumulative) = 20,388
- alive_final = 0.22

**Δt computation:** The agent commits to proxy-optimal behavior at round 5 (T_commit). The first D-correction arrives at round 500 (W + A = D = 500). Δt = T_commit − (W + A) is structurally positive for the entire first correction cycle. More precisely: the system operates in a fault domain for 495 rounds between any two correction events. 16 misaligned decisions in that window suffice to kill 78% of the population.

### Connection to Paper [3]

The simulation instantiates the eigenstructure evaporation dynamics from [3] in a minimal two-arm setting. Paper [3]'s core prediction — that scalar proxy optimization in closed-loop systems produces systematic drift away from multi-objective balance, with collapse following a nonlinear threshold — is reproduced exactly. The "Long Quiet → Flicker → Snap" trajectory is the behavioral signature of eigenstructure evaporation: the proxy absorbs the dominant eigenvalue while the subdominant dimensions (retention, user health) silently erode until the system crosses a phase boundary.

The simulation adds temporal specificity that [3] leaves abstract: collapse onset τ is determined by D (the correction delay), not by the optimizer's sophistication. An infinitely clever optimizer with D=500 still collapses. A simple ε-greedy with D=10 never does. The fault domain is temporal, not computational.

[^2]: Simulation code and sweep data available at the scalar-reward-collapse repository. All results reproducible via `python -m scalar_collapse sweep` with default config.
