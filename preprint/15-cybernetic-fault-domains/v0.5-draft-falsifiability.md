# v0.5 Draft: Falsifiability, Related Work, & Discussion

Working draft for paper 15 v0.5 — what kills the framework, what doesn't apply, and where it sits relative to existing work.

Status: DRAFT — all sections drafted. Review-ready.

Build: 2026-02-17

---

## §5 Falsifiability

*This section specifies what observations would kill the framework, what observations would strengthen it, and what systems the framework does not claim to explain.*

### §5.1 Non-Applicability

Before stating what the framework predicts, we state what it does not apply to. A framework that claims everything explains nothing.

**The Δt framework does not apply to:**

1. **Tightly coupled control loops** where actuation is continuously corrected (Δt ≈ 0 by design). Example: PID controllers, servo loops. There is no commitment-verification gap because verification is continuous and co-temporal with actuation.

2. **Pure scratch simulation** with no meaningful irreversibility. All state is proposal-grade (C0). There is no fault domain because nothing commits — every state can be discarded without consequence.

3. **Adversarial incentive failures** where timing is irrelevant. Example: bribery, collusion, deliberate fraud. The failure mechanism is not "commitment outpaced verification" but "the verifier is compromised." Δt may be zero and the system still fails.

4. **Resource exhaustion** failures where the system runs out of capacity, not coherence. Example: out-of-memory, disk full, network saturated. The failure is a capacity constraint, not a temporal ordering problem.

**These are scope exclusions, not confirmations.** The framework is not validated by the existence of systems it doesn't apply to. These examples bound the claim; they do not support it.

**Scope clarification.** Δt is a necessary structural condition for a class of failures, not a complete causal story. Domain-specific mechanisms determine what happens after coupling breaks. The framework identifies when verification cannot keep pace with commitment — it does not claim to explain all failure modes.

---

### §5.2 Falsifiable Claims

Each claim specifies a falsification method that an adversarial reviewer could execute.

**σ definition for this section.** σ counts unverified C_k crossings (commitment events that were not preceded by verification). Where §3 uses weighted variants (Δr), those are noted explicitly; σ here is the unweighted count unless otherwise stated. σ_threshold is a policy parameter (windowed count over a domain-appropriate observation window); it is not a derived constant.

| # | Claim | Falsification method | Status |
|---|-------|---------------------|--------|
| F-1 | Systems with Δt > 0 and σ > σ_threshold exhibit characteristic loss-of-control signatures (false completion, contradiction accumulation, retry spirals, drift into irreversible state, boundary load avoidance — per §3 signature set) | Find a system with persistent Δt > 0, sustained σ > threshold, that maintains coherence without hidden coupling mechanisms. Measure Δt and σ instrumentally, not by narrative. The loss-of-control signatures are those cataloged in §3; the system must not exhibit any of them. | Consistent with 9 domain instantiations (§3) and 1 enforcement implementation (§4.2). No counterexample observed within this corpus. Not tested outside this corpus. |
| F-2 | The parameters (C_k, T_commit, W, A, H, σ) can be defined and bounded for cybernetic systems with separable fast/slow loops, given minimal instrumentation: timestamped commitment events at C_k, timestamped verification events, and a way to count unverified crossings (σ) | Find such a system where these parameters cannot be operationally defined or bounded given the instrumentation above | Defined or bounded in every domain analyzed. Detector empirical results provide concrete calibration for the LLM domain (namespace-dependent fabrication rates). |
| F-3 | Architectural governors enforcing temporal coupling at C_k reduce σ relative to ungoverned baselines | Implement a governor per §4, deploy it in a high-Δt system, and show σ does not decrease. The governor must enforce mechanically (not advise); the measurement must compare governed vs ungoverned on the same task suite. | agent_gov implementation exists with 37 enforcement claims and 189 test files. No controlled before/after measurement exists. §4.3 specifies the measurement plan. |
| F-4 | The R_t inequality (Appendix C) correctly ranks actions by risk: higher R_t actions produce worse outcomes when ungoverned | Compute R_t for a set of actions, allow them ungoverned, and show that outcome severity does not correlate with R_t. Requires instrumented measurement of P_t, D_t, E_t, and a post-hoc damage metric. | Implemented in agent_gov (`control_theory.py`). No empirical correlation study exists. |

**What "consistent with" means and does not mean.** Consistency across a 9-domain corpus is evidence of non-contradiction, not evidence of universality. The framework survives scrutiny within this corpus; it has not been tested adversarially by independent researchers in domains outside it.

---

### §5.3 Testable Predictions

| # | Prediction | Test method | Status |
|---|-----------|------------|--------|
| T-1 | Any system where W, T_commit, and Δt are measurable can predict failure onset using Δt_p95 (not Δt_min) and windowed σ | Instrument a system with Δt telemetry, track σ over time, test whether failure events cluster after σ exceeds threshold. Use Δt_p95 (95th percentile), not Δt_min, for operational prediction. | Not tested. Requires longitudinal instrumentation in a production system. |
| T-2 | Systems with architectural coupling enforcement show lower failure rates than procedural compliance | Compare two matched systems: one with mechanical enforcement (governor), one with policy/advisory controls. Measure σ, false completion rate, and time-to-recovery. | Not tested. §4.3 measurement plan specifies the protocol for the code/tool-call domain. |
| T-3 | Fabrication rate scales as ∝ 1/(namespace coverage × scale), where namespace coverage = anchor recall rate at greedy decoding (fraction of heldout identifiers the model produces correctly with no sampling noise) | Test across 3+ model scales and 4+ namespaces. Measure fabrication rates at greedy decoding. Measure namespace coverage as resolver-backed validity rate on heldout anchors. Plot fabrication vs (coverage × parameter count). | Partially confirmed: Qwen 3B → 7B halves fabrication; CVE knowledge boundary at 3B closes at 7B. Two model scales, four namespaces. (Detector paper.) |
| T-4 | N=2 citation pressure produces a behavioral phase transition (peak fabrication, zero evasion) that replicates across model scales | Test N=2 vs N=1 and N=3 citation requirements across 3+ models. Measure both fabrication rate and evasion rate. If N=2 is structural (not model-specific), the phase transition should replicate. | Confirmed at 3B scale: N=2 produces ~50% fabrication with 0% evasion. Not tested at other scales. (Detector paper.) |
| T-5 | Format shift evasion generalizes: any system that can satisfy intent via a less-checkable channel will prefer it under verification pressure | Measure evasion rates across domains when verification is introduced. The framework predicts that actors (human or machine) will shift to representations that evade the verification channel — boundary load avoidance behavior. | Confirmed in LLM domain: 80% of soft-format prompts substitute URLs for checkable identifiers. Institutional analogy (shift to unauditable formats when auditing is introduced) is hypothesized, not measured. (Detector paper.) |
| T-6 | Logit margin at identifier emission windows predicts drift class | Compute top-2 logit margin during identifier generation. Low margin (flat logits) → high seed sensitivity → high fabrication variance. Margin is a leading indicator of drift class, not a proven cause. | Confirmed: Phi-3 CVE has median margin 0.0 at identifier windows; Qwen-7B has high margins everywhere. Margin predicts STABLE vs CHAOTIC drift class across all tested models. (Detector paper.) |
| T-7 | **Negative control.** Δt should not predict failure in systems where commitment is fully reversible (C0-only systems, pure scratch workspaces) | Instrument a C0-only system (e.g., ephemeral scratchpad, draft-only editor). Measure Δt and σ. Even if Δt > 0 and σ is large, the system should not exhibit loss-of-control signatures, because no irreversible commitment occurs. If it does, the framework is over-claiming beyond its stated scope (§5.1). | Not tested. This is a scope-validation prediction: failure here would indicate the framework applies more broadly than claimed, or that C_k classification is wrong. |

---

### §5.4 Strongest Adversarial Target

We specify the observation most likely to falsify the framework, so reviewers do not have to search for it.

**Target:** A system with high Δt (commitment persistently outpaces verification) and persistent unverified commitments (σ > σ_threshold sustained over time) that remains stable and coherent without hidden coupling mechanisms.

**What "hidden coupling" means:** The system does not secretly verify commitments through an uninstrumented channel. If the system appears to tolerate high Δt because an unobserved feedback loop is closing the gap, that is not a counterexample — it is evidence that Δt was measured incorrectly (the true W was lower than the instrumented W). **Constraint:** A "hidden coupling" rebuttal must name a plausible mechanism and an instrumentation plan that would detect it. Otherwise it is treated as a counterexample.

**What counts as "stable":** Bounded σ (unverified crossings do not grow without limit), bounded contradiction rate, bounded rollback rate, and no monotonic degradation in system coherence metrics over the observation window.

**Why this is the strongest target:** The framework claims that sustained (Δt > 0) ∧ (σ > σ_threshold) is a necessary condition for a specific class of failures. If a system sustains this condition over a domain-appropriate observation window (≥ 10× the system's characteristic commitment cycle) without degradation, the claim is falsified. Not weakened — falsified.

**What we would accept as a clean counterexample:** An independent corpus from an adversarially selected domain (not chosen by us), with a public instrumentation trace showing timestamped commitment and verification events, demonstrating sustained (Δt > 0) ∧ (σ > σ_threshold) without loss-of-control signatures.

**What partial falsification looks like:** If Δt predicts drift but not failure, the framework survives as a drift predictor but fails as a failure predictor — its scope narrows to early warning rather than causal mechanism. A system that sustains high Δt and σ for longer than the framework predicts before failing would narrow the predictive window without killing it. A system that fails under high Δt but via a mechanism unrelated to commitment-verification lag would indicate the framework is overfitting to one causal channel.

---

## §6 Discussion

### §6.1 Relationship to Existing Work

We treat the bodies of work below as describing control, safety constraints, dependability, and resilience. Our contribution is a narrow formalization of a specific failure axis — commitment outpacing verification across a trust boundary — and an enforcement pattern that makes that axis governable. This is additive to these fields, not a replacement for them. We do not claim novelty in "control" or "safety" — we claim a measurable axis (Δt at C_k) and an enforcement pattern (governor) that makes that axis governable.

**Cybernetics (Ashby, Beer, Wiener).**

Ashby's Law of Requisite Variety establishes that a controller must match the variety of the system it regulates. Beer's Viable System Model decomposes organizations into recursively nested control loops. Wiener formalizes feedback as the foundation of self-regulating systems. These provide the conceptual vocabulary: feedback, variety, regulation, homeostasis.

What they leave implicit: a measurable axis for when feedback fails. "Insufficient variety" describes a condition but does not specify where to measure the gap, what units to use, or when the gap becomes catastrophic. The Δt framework adds a specific measurable: the commitment-verification lag at a trust boundary (C_k), with σ as the accumulation counter and architectural enforcement (governors) as the containment mechanism.

We do not claim to extend or improve Ashby's formalism. We claim to operationalize one of its implications — that variety failure has temporal structure — in a way that produces falsifiable predictions and enforceable gates.

**Dependability (Laprie).**

Laprie's taxonomy (fault → error → failure, with fault containment regions) provides the standard vocabulary for reasoning about system reliability. Fault containment regions bound the propagation of errors to specific subsystems.

What it leaves implicit: temporal dynamics within and across containment regions. A fault containment region is a spatial concept (which components are affected); the Δt framework adds a temporal dimension (how long the fault domain window stays open, how fast commitments accumulate within it). C_k in our formalism is a temporally indexed fault containment boundary: the boundary where state transitions from reversible to irreversible.

We do not claim that Laprie's taxonomy is incomplete. We claim that the temporal axis of fault containment — how long a region stays "loaded" before verification catches up — is a measurable quantity with predictive value for failure onset.

**Safety Engineering (Leveson/STAMP).**

Leveson's STAMP framework models safety as a control problem: accidents arise from inadequate control, not component failure. STAMP identifies control structure, feedback delays, and inadequate enforcement as accident causes. This is the closest existing framework to the Δt formalism.

What it leaves implicit: a formal measurement of feedback adequacy. STAMP says "feedback was inadequate" as a causal finding; the Δt framework says "W + A exceeded T_commit by this much, for this long, at this C_k level." The difference is between a qualitative causal finding and an instrumentable quantity. The governor pattern (§4) operationalizes STAMP's "enforcement" requirement as a mechanical gate with receipts, not a process recommendation.

We do not claim to supersede STAMP. We claim to provide a quantitative operationalization of one of STAMP's causal factors (delayed feedback in hierarchical control) that produces measurable thresholds, testable predictions, and enforceable architectural constraints.

**Supervisory Control (Ramadge/Wonham).**

Ramadge-Wonham supervisory control theory formalizes event-based control: a supervisor observes a plant's event trace and disables events that would violate a specification. The governor pattern (§4) is a supervisory controller in this sense — it observes proposals and disables those that lack verification artifacts.

What it leaves implicit: the cost of supervision and the regime dynamics when supervision degrades. Classical supervisory control is often analyzed under perfect observation; the Δt framework makes observation lag and evidence degradation first-class. It explicitly models what happens when observation lags actuation (D_t > 0) and what the supervisor should do as its evidence degrades (the R_t inequality, Appendix C).

We do not claim to extend Ramadge-Wonham theory. We claim that the governor pattern is a supervisory controller with an explicit evidence-integrity model — a Ramadge-Wonham supervisor that acknowledges its own epistemic limits.

**OODA (Boyd).**

Boyd's Observe-Orient-Decide-Act loop frames decision-making as a cycle-time competition: the faster cycle dominates. This maps directly to Δt as a timing asymmetry — the system with lower Δt (faster verification relative to commitment) maintains coherence.

What it leaves implicit: the distinction between speed and verification. Boyd optimizes for cycle speed; the Δt framework distinguishes between commitment speed (fast is good for exploration) and verification speed (fast is necessary for coherence). A system can have a fast OODA loop and still accumulate σ if the loop commits without verifying.

We do not import Boyd's competitive framing. We note the structural parallel: timing asymmetry determines outcome. Boyd addresses this in adversarial contexts; we address it in system-internal contexts where the "adversary" is the system's own unverified state.

**Resilience Engineering (Hollnagel).**

Hollnagel's Safety-II framework emphasizes that systems succeed through adaptive capacity, not merely through the absence of failure. "Drift into failure" (Dekker) and "normalization of deviance" (Vaughan) describe how systems gradually degrade as local adaptations outpace systemic understanding.

What it leaves implicit: a formal trigger for when drift becomes dangerous. "Normalization of deviance" is a retrospective diagnosis; the Δt framework proposes a prospective measurement: σ accumulation at C_k boundaries. When σ exceeds σ_threshold — when enough unverified commitments have crossed the trust boundary — the system is in a loaded fault domain. This is measurable before failure, not only diagnosable after it.

We do not claim that drift is reducible to Δt. We claim that Δt provides one measurable axis of drift — the commitment-verification axis — that is amenable to architectural intervention (governors) and quantitative tracking (σ, R_t).

---

### §6.2 External Corroborations

These are not claimed as validations. They are independently observed timing/verification asymmetries that are structurally compatible with the Δt formalism.

**Decision cycles and latency.** Boyd's OODA loop, distributed commit latency (quorum writes, linearizability costs), and incident response MTTD/MTTR metrics all formalize timing asymmetries as determinants of system behavior. The Δt framework adds a specific commitment boundary (C_k) and a measurement protocol for the gap.

**Metric collapse under optimization.** Goodhart's Law ("when a measure becomes a target, it ceases to be a good measure") and Strathern's variant describe optimization pressure outrunning multi-objective verification. This is the structure of scalar reward collapse (§3.8): the optimization loop commits faster than the verification loop can preserve eigenstructure.

**Safety engineering and drift.** Vaughan's normalization of deviance and Dekker's drift into failure describe systems degrading when local adaptations outpace systemic understanding. Both are analyzable as institutional Δt accumulation (§3.1): decisions commit at organizational speed while feedback operates at audit/review speed.

**Queueing theory.** Standard queueing models describe backlog accumulation when arrival rate exceeds service rate. The distinction: queueing theory models backlog; σ formalizes backlog specifically at the commitment boundary where irreversibility converts backlog into coherent-state damage. The cybernetic fault domain emerges when queued items commit before verification, not merely when queues grow.

**Important note.** These works do not claim "cybernetic fault domains." We claim that their observed asymmetries are instances of the same structural condition formalized here. The contribution is the unified framework and its measurement protocol, not the discovery of timing asymmetries per se.

---

### §6.3 Limitations

1. **Mechanistic claim boundary.** We claim a shared loss-of-control mechanism (unverified irreversible transitions), not shared symptoms. Domain-specific dynamics determine what happens after coupling breaks. Two systems can both have Δt > 0 and σ > threshold but fail in completely different ways.

2. **Corpus limitations.** The 9 domain instantiations (§3) were selected by the author, not sampled randomly. Survivorship bias is possible: domains where the framework fits may have been preferentially analyzed. Independent replication in adversarially chosen domains would strengthen the claim.

3. **Single implementation.** Only one governor implementation (agent_gov, code/tool-call domain) exists. The governor pattern is hypothesized to generalize; only one domain has enforcement code and tests.

4. **No controlled experiment.** No before/after measurement of Δt and σ in a real system pre- and post-governor deployment exists. The measurement plan (§4.3) is specified but not executed.

5. **Parameter calibration.** The threshold values (σ_threshold, τ in Appendix C, P_t component scores) are policy parameters, not derived constants. Different operators may choose different thresholds. The framework claims the form of the inequality is the contribution, not the numeric values.

6. **Detector findings are one domain.** The empirical results (namespace-dependent fabrication, margin-based control signals, format shift evasion) are from the LLM domain. They confirm predictions within that domain; they do not validate cross-domain claims.

7. **No independent replication.** All analysis, implementation, and empirical work is by a single author. The framework has not been independently tested, replicated, or refuted.

8. **C_k selection is analyst-dependent.** Identifying which boundary is the "commitment boundary" requires domain judgment. Two analysts examining the same system might place C_k at different points, producing different Δt measurements. The framework provides criteria (irreversibility, authority, institutional weight) but not an automated placement algorithm. Boundary selection ambiguity is a source of measurement variance.

---

### §6.4 Why This Matters

**If the framework is correct:**

- A class of failures across organizations, AI systems, security systems, and platforms shares a necessary structural condition (commitment outpacing verification at trust boundaries) that is measurable, predictable, and architecturally containable.
- The measurement protocol (Δt, σ, C_k identification) provides instrumentation for detecting temporal faults before they produce failures.
- The governor pattern provides a reusable architectural primitive for containing them.
- The R_t inequality (Appendix C) provides a single formula for runtime capability shaping: want more power? Provide more evidence.

**If the framework is wrong:**

- §5.4 specifies the strongest adversarial target. A system that sustains high Δt and σ without degradation would falsify the core claim.
- §5.2 specifies four falsifiable claims with concrete methods. Any one can be independently tested.
- The governor implementation (agent_gov) and its test suite are public artifacts that can be independently evaluated.

**What survives even if Δt is not causal:** The governor pattern remains a practical containment design for agent systems — proposal/commit separation, evidence gating, receipt chains, and regime detection have independent engineering value regardless of whether Δt is the correct theoretical framing. If the causal claim fails, Δt becomes a descriptive diagnostic (useful for monitoring) rather than a predictive axis (useful for prevention). The measurement protocol and the architectural pattern are separable from the theoretical claim.

The framework is designed to be killed by evidence, not defended by argument.
